{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "MakeMultipleColumnsFeatures.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyOY/fbbJoVhk0oamJ+vgQKv",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/adnansee/PythonTensorflow2.0/blob/master/MakeMultipleColumnsFeatures.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "obE9K8rqO6E9",
        "colab_type": "code",
        "outputId": "a8971513-e070-4342-cc17-b43418159c93",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        }
      },
      "source": [
        "!pip install -q sklearn\n",
        "!pip install -q category-encoders\n",
        "%tensorflow_version 2.x\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import tensorflow as tf\n",
        "from sklearn import preprocessing\n",
        "from tensorflow import feature_column\n",
        "from tensorflow.keras import layers\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import OneHotEncoder\n",
        "from sklearn.compose import ColumnTransformer\n",
        "from tensorflow import keras\n",
        "import matplotlib.pyplot as plt\n",
        "from scipy.stats import gaussian_kde\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.feature_extraction import FeatureHasher\n",
        "import category_encoders as ce\n",
        "\n",
        "# LOAD DATA IN CSV FORM (FOR OTHER FORMS CHANGE PANDAS METHOD) - ALSO CLEAN THE COLUMN NAMES AND REMOVE 'UNNAMED' COLUMNS - VISULIZE\n",
        "\n",
        "URL = 'https://raw.githubusercontent.com/adnansee/csvdata/master/Workinghours(1).csv'\n",
        "dataframe = pd.read_csv(URL, header=0)\n",
        "dataframe = dataframe.loc[:, ~dataframe.columns.str.contains('^Unnamed')]\n",
        "dataframe.columns = dataframe.columns.str.strip().str.lower().str.replace(' ', '_').str.replace('(', '').str.replace(')', '')\n",
        "dataframe.head(5)\n",
        "dataframe.education = dataframe.education.astype('float64')\n",
        "dataframe2 = dataframe.copy()\n",
        "\n",
        "allDataFramesAndSets = []\n",
        "finalModel = []\n",
        "allFeatures = []\n",
        "dataframe.head()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>hours</th>\n",
              "      <th>income</th>\n",
              "      <th>age</th>\n",
              "      <th>education</th>\n",
              "      <th>child5</th>\n",
              "      <th>child13</th>\n",
              "      <th>child17</th>\n",
              "      <th>nonwhite</th>\n",
              "      <th>owned</th>\n",
              "      <th>mortgage</th>\n",
              "      <th>occupation</th>\n",
              "      <th>unemp</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>2000</td>\n",
              "      <td>350</td>\n",
              "      <td>26</td>\n",
              "      <td>12.0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>swcc</td>\n",
              "      <td>7</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>390</td>\n",
              "      <td>241</td>\n",
              "      <td>29</td>\n",
              "      <td>8.0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>other</td>\n",
              "      <td>4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>1900</td>\n",
              "      <td>160</td>\n",
              "      <td>33</td>\n",
              "      <td>10.0</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>swcc</td>\n",
              "      <td>7</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0</td>\n",
              "      <td>80</td>\n",
              "      <td>20</td>\n",
              "      <td>9.0</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>other</td>\n",
              "      <td>7</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>3177</td>\n",
              "      <td>456</td>\n",
              "      <td>33</td>\n",
              "      <td>12.0</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>swcc</td>\n",
              "      <td>7</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   hours  income  age  education  ...  owned  mortgage  occupation  unemp\n",
              "0   2000     350   26       12.0  ...      1         1        swcc      7\n",
              "1    390     241   29        8.0  ...      1         1       other      4\n",
              "2   1900     160   33       10.0  ...      1         0        swcc      7\n",
              "3      0      80   20        9.0  ...      1         1       other      7\n",
              "4   3177     456   33       12.0  ...      1         1        swcc      7\n",
              "\n",
              "[5 rows x 12 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 1
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Rw3ENpFGRejO",
        "colab_type": "code",
        "outputId": "702097ce-2375-4c59-f12b-d44bbc6da58b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "def makeManyFeaturesColumns(dataframe, target, categoricalColumn):\n",
        "\n",
        "    #WOE ENCODING\n",
        "    woe_df = dataframe.groupby(categoricalColumn)[target].mean()\n",
        "    woe_df = pd.DataFrame(woe_df)\n",
        "    woe_df = woe_df.rename(columns  = {target : 'Good'})\n",
        "    woe_df['Bad'] = 1 - woe_df.Good\n",
        "    woe_df['Bad'] = np.where(woe_df['Bad'] == 0, 0.000001, woe_df['Bad'])\n",
        "    woe_df['WoE'] = np.log(woe_df.Good / woe_df.Bad)\n",
        "    dataframe.loc[:,'woe_'+categoricalColumn] = dataframe[categoricalColumn].map(woe_df['WoE'])\n",
        "\n",
        "    #POE ENCODING\n",
        "    poe_df = dataframe.groupby(categoricalColumn)[target].mean()\n",
        "    poe_df = pd.DataFrame(poe_df)\n",
        "    poe_df = poe_df.rename(columns  = {target : 'Good'})\n",
        "    poe_df['Bad'] = 1 - poe_df.Good\n",
        "    poe_df['Bad'] = np.where(poe_df['Bad'] == 0, 0.000001, poe_df['Bad'])\n",
        "    poe_df['PoE'] = poe_df.Good / poe_df.Bad\n",
        "    dataframe.loc[:,'poe_'+categoricalColumn] = dataframe[categoricalColumn].map(poe_df['PoE'])\n",
        "\n",
        "    #MEAN ENCODING\n",
        "    meanEncoder = dataframe.groupby(categoricalColumn)[target].mean()\n",
        "    dataframe.loc[:,'mean_'+categoricalColumn] = dataframe[categoricalColumn].map(meanEncoder)\n",
        "\n",
        "    #LABEL ENCODING\n",
        "    labelEncoder = LabelEncoder()\n",
        "    dataframe.loc[:,'label_'+categoricalColumn] = labelEncoder.fit_transform(dataframe[categoricalColumn])\n",
        "\n",
        "    #FREQUENCY ENCODING\n",
        "    frequencyEncoding = dataframe.groupby(categoricalColumn).size()/len(dataframe)\n",
        "    dataframe.loc[:,'frequency_'+categoricalColumn] = dataframe[categoricalColumn].map(frequencyEncoding)\n",
        "\n",
        "#BINARY ENCODING\n",
        "def binaryEncoder(dataframe, categoricalColumn):\n",
        "    ce_binary = ce.BinaryEncoder(cols = categoricalColumn)\n",
        "    return ce_binary.fit_transform(dataframe[categoricalColumn])\n",
        "\n",
        "# MOST OFTEN NOMINAL DATA\n",
        "def oneHotEncoder(dataframe, categoricalColumn):\n",
        "    columnName_bin = feature_column.categorical_column_with_vocabulary_list(\n",
        "    categoricalColumn, dataframe[categoricalColumn].unique())\n",
        "    columnName_bin_one_hot = feature_column.indicator_column(columnName_bin)\n",
        "    return columnName_bin_one_hot\n",
        "  \n",
        "#ONE HOT EMBEDDING ENCODING\n",
        "def oneHotEmbbEncoder(dataframe, categoricalColumn):\n",
        "    columnName_bin = feature_column.categorical_column_with_vocabulary_list(\n",
        "    categoricalColumn, dataframe[categoricalColumn].unique())\n",
        "    columnName_bin_one_hot = feature_column.embedding_column(columnName_bin, dimension= (dataframe[categoricalColumn].value_counts().size))\n",
        "    return columnName_bin_one_hot\n",
        "\n",
        "#HASHED ENCODING\n",
        "def hashedColumnEncoder(dataframe, categoricalColumn):\n",
        "    hashed = feature_column.categorical_column_with_hash_bucket(\n",
        "    categoricalColumn, hash_bucket_size=dataframe[categoricalColumn].value_counts().size)\n",
        "    return hashed\n",
        "    \n",
        "\n",
        "#NORMALISING\n",
        "def normalize(columnName, dataframe):\n",
        "    x = dataframe[[columnName]].values.astype(float)\n",
        "    # Create a minimum and maximum processor object\n",
        "    min_max_scaler = preprocessing.MinMaxScaler()\n",
        "    # Create an object to transform the data to fit minmax processor\n",
        "    x_scaled = min_max_scaler.fit_transform(x)\n",
        "    # Run the normalizer on the dataframe\n",
        "    dataframe[columnName] = x_scaled\n",
        "\n",
        "#CREATE ONEHOT EMBEDDINGS\n",
        "def createOneHotEmbeddingColumns(dataframe, categoricalColumn):\n",
        "    ohc = oneHotEncoder(dataframe, categoricalColumn)\n",
        "    ohec = oneHotEmbbEncoder(dataframe, categoricalColumn)\n",
        "    hc = hashedColumnEncoder(dataframe, categoricalColumn)\n",
        "    be = binaryEncoder(dataframe, categoricalColumn)\n",
        "    embbOjtArray = [ohc,ohec,hc,be]\n",
        "    print((ohc, ohec, hc, be))\n",
        "    #allFeatures.extend((ohc, ohec, hc, be))\n",
        "    return embbOjtArray\n",
        "\n",
        "\n",
        "#CONVERT DATAFRAME TO DATASET\n",
        "\n",
        "def df_to_dataset(dataframe, labelName, shuffle=True, batch_size=32):\n",
        "  dataframe = dataframe.copy()\n",
        "  labels = dataframe.pop(labelName)\n",
        "  ds = tf.data.Dataset.from_tensor_slices((dict(dataframe), labels))\n",
        "  if shuffle:\n",
        "    ds = ds.shuffle(buffer_size=len(dataframe))\n",
        "  ds = ds.batch(batch_size)\n",
        "  return ds\n",
        "\n",
        "                                                  \n",
        "#FILL NAN WITH MEAN VALUES FOR NUMERICAL COLUMNS\n",
        "\n",
        "def fillNanWithMean(column):\n",
        "  #for column in dataframe.iteritems():\n",
        "    dataframe[column].fillna((dataframe[column].mean()), inplace=True)\n",
        "\n",
        "\n",
        "#MAKE ALL THE FEATURES\n",
        "def makeAll(dataframe, target):\n",
        "  \n",
        "  \n",
        "  for column in dataframe:\n",
        "    if dataframe[column].dtype == 'object': \n",
        "      originalDtype = dataframe[column].dtype\n",
        "      makeManyFeaturesColumns(dataframe, target, column)\n",
        "      #allFeatures.append((column))\n",
        "      print(column, ' - ', len(dataframe[column].value_counts()),' different values and was of',originalDtype, 'type. FEATURE COLUMNS CREATED (POE - WOE - EMBB - LAB - MEAN - LABEL - FREQ)')\n",
        "       \n",
        "  for column in dataframe: \n",
        "    if dataframe[column].dtype == 'int64' or dataframe[column].dtype == 'float64':\n",
        "      originalDtype = dataframe[column].dtype\n",
        "      if len(dataframe[column].value_counts()) > 2:\n",
        "        normalize(column, dataframe)\n",
        "        print(column, ' - ', len(dataframe[column].value_counts()),' different values and of',originalDtype, 'type was normalised ')\n",
        "  \n",
        "\n",
        "  allFeatures.extend((dataframe.columns.values))\n",
        "  allFeatures.remove(target)\n",
        "\n",
        " # allFeatures.extend((dataframe.columns.values))\n",
        "  for column in dataframe:\n",
        "    if dataframe[column].dtype == 'object': \n",
        "      allFeatures.remove(column)     \n",
        "\n",
        "print(allFeatures)\n",
        "# SPLIT THE DATA\n",
        "def splitDataFrame(dataframe, batch_size, label):\n",
        "  train, test = train_test_split(dataframe, test_size=0.2)\n",
        "  train, val = train_test_split(train, test_size=0.2)\n",
        "  print(len(train), 'train examples')\n",
        "  print(len(val), 'validation examples')\n",
        "  print(len(test), 'test examples')\n",
        "  \n",
        "  train_ds = df_to_dataset(train, label, batch_size=batch_size)\n",
        "  val_ds = df_to_dataset(val, label, shuffle=False, batch_size=batch_size)\n",
        "  test_ds = df_to_dataset(test, label, shuffle=False, batch_size=batch_size)\n",
        "\n",
        "  trainTestData = [train_ds, val_ds, test_ds]\n",
        "  allDataFramesAndSets.extend((train_ds, val_ds, test_ds, train, test))\n",
        "  return trainTestData\n",
        "\n",
        "# MODEL COMPILE AND FIT **************************************************************************************************************************\n",
        "\n",
        "# CREATE THE FEATURE LAYER WITH THE UPDATED COLUMNS\n",
        "def compileFitModel(dataframe, label):\n",
        "  feature_columns = []\n",
        "  #allFeatures.remove(label)\n",
        "  \n",
        "  for header in allFeatures:#['income','age','child13','unemp','woe_occupation','nonwhite','hours', 'education', 'owned','child5','child17',]:\n",
        "    feature_columns.append(feature_column.numeric_column(header))\n",
        "  feature_layer = tf.keras.layers.DenseFeatures(feature_columns)\n",
        "\n",
        "  feature_layer = tf.keras.layers.DenseFeatures(feature_columns)\n",
        "\n",
        "  # ADD OTHER LAYERS DEPENDING ON MODEL\n",
        "  model = keras.Sequential([\n",
        "      feature_layer,  # input layer (1)\n",
        "      keras.layers.Dense(128, activation='relu'),  # hidden layer (2)\n",
        "      keras.layers.Dense(128, activation='relu'),\n",
        "      keras.layers.Dense(1) # output layer (3)\n",
        "      #keras.layers.Dense(4, activation='softmax')\n",
        "  ])\n",
        "\n",
        "  # COMPILE MODEL\n",
        "  model.compile(optimizer='adam',\n",
        "                  #loss='sparse_categorical_crossentropy',\n",
        "                  #loss=tf.keras.losses.CategoricalCrossentropy(),\n",
        "                  #loss=tf.keras.losses.KLDivergence(),\n",
        "                  loss=tf.keras.losses.BinaryCrossentropy(from_logits=False),\n",
        "                  #loss=tf.keras.losses.MeanAbsoluteError(),\n",
        "                  #loss=tf.keras.losses.Poisson(),\n",
        "                  metrics=['accuracy'])\n",
        "\n",
        "  #GET THE DATA\n",
        "  dataframeArray = splitDataFrame(dataframe, 32, label)\n",
        "  \n",
        "  \n",
        "\n",
        "  \n",
        "  # FIR MODEL\n",
        "  modelHis = model.fit((dataframeArray[0]),\n",
        "          validation_data=(dataframeArray[1]),\n",
        "          epochs=10)  # we pass the data, labels and epochs and watch the magic!\n",
        "  finalModel.append(model)\n",
        "  finalModel.append(modelHis)\n",
        "\n",
        "  return model    \n",
        "\n",
        "#                                                               SHOW HIT RESULTS IN PERCENTAGE\n",
        "\n",
        "#????????????????????????????????\n",
        "\n",
        "def showHitResult(test_ds, label, test, model):\n",
        "\n",
        "  labels = pd.DataFrame(test[label].astype('float64'))\n",
        "  \n",
        "  \n",
        "  results = model.predict(test_ds)\n",
        "  results = pd.DataFrame(results)\n",
        "  results[results>=0.5]=1\n",
        "  results[results<0.5]=0\n",
        "  \n",
        "  resultsArray = results.rename(columns={0:label})\n",
        "  labels = labels.reset_index(drop=True)\n",
        "  labelsFloat = test[label].astype('float64')\n",
        "  resultsArray.set_index(label)\n",
        "\n",
        "  print('Real target results')\n",
        "  print(labels)\n",
        "  print('Predicted results relow')\n",
        "  print(resultsArray)\n",
        "\n",
        "  A = resultsArray\n",
        "  B = labels\n",
        "  number_of_equal_elements = np.sum(A==B)\n",
        "  total_elements = np.multiply(*A.shape)\n",
        "  percentage = number_of_equal_elements/total_elements\n",
        "  print(percentage*100)\n",
        "\n",
        "\n",
        "  print('total number of elements: \\t\\t\\t{}'.format(total_elements))\n",
        "  print('number of identical elements: \\t\\t{}'.format(number_of_equal_elements))\n",
        "  print('number of different elements: \\t\\t{}'.format(total_elements-number_of_equal_elements))\n",
        "  print((percentage)*100.0)\n",
        "  #print(dr.head(10))\n",
        "\n",
        "  \n",
        "\n",
        "#METHOD TO SHOW ALL CATEGORIES FOR EVERY COLUMN IN THE DATAFRAME\n",
        "def showAllCategories(dataframe):\n",
        "    for column in dataframe:\n",
        "      print(dataframe[column].value_counts())\n",
        "\n",
        "#print('Train: %.3f, Test: %.3f' % (len(train_ds), len(test_ds))\n",
        "#PLOT THE LOSS AND ACCURACY\n",
        "def plotLossAccuracy(model):\n",
        "  plt.title('Loss')\n",
        "  plt.plot(model.history['loss'], label='Train')\n",
        "  plt.plot(model.history['val_loss'], label='Test')\n",
        "  plt.legend()\n",
        "  plt.show()\n",
        "  plt.title('Accuracy')\n",
        "  plt.plot(model.history['accuracy'], label='Train')\n",
        "  plt.plot(model.history['val_accuracy'], label='Test')\n",
        "  plt.legend()\n",
        "  plt.show()\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['hours', 'income', 'age', 'education', 'child5', 'child13', 'child17', 'nonwhite', 'owned', 'unemp', 'woe_occupation', 'poe_occupation', 'mean_occupation', 'label_occupation', 'frequency_occupation']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Plq9T5DU6jij",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "makeAll(dataframe, 'mortgage')\n",
        "onehotfeatures = createOneHotEmbeddingColumns(dataframe, 'occupation')\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TlI7YIXUZzFZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "compileFitModel(dataframe, 'mortgage')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sOMn2WqoAnGn",
        "colab_type": "code",
        "outputId": "f2aac70c-00e0-4591-9a25-0bc2318a308b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        }
      },
      "source": [
        "finalModel"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[<tensorflow.python.keras.engine.sequential.Sequential at 0x7ff94e046ac8>,\n",
              " <tensorflow.python.keras.callbacks.History at 0x7ff94ce26c50>]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZRE1AcZa39Fe",
        "colab_type": "code",
        "outputId": "704d9dcf-d68b-4abc-f797-1dbccff91c13",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 236
        }
      },
      "source": [
        "plotLossAccuracy(finalModel[1])\n",
        "\n",
        "#  TEST ACCURACY\n",
        "loss, accuracy = finalModel[0].evaluate(allDataFramesAndSets[2])\n",
        "print(\"Accuracy\", accuracy * 100)\n",
        "\n",
        "showHitResult(allDataFramesAndSets[2],'mortgage',allDataFramesAndSets[4], finalModel[0])\n",
        "\n",
        "finalModel[0].predict(allDataFramesAndSets[0])\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "error",
          "ename": "IndexError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-6-6d06f973a63b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mplotLossAccuracy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfinalModel\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;31m#  TEST ACCURACY\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maccuracy\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfinalModel\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mevaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mallDataFramesAndSets\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Accuracy\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maccuracy\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0;36m100\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mIndexError\u001b[0m: list index out of range"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tTnM-PnrGuOF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "print(finalModel[0])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_RN9IWBOApqe",
        "colab_type": "code",
        "outputId": "c8b5cc07-5efb-4588-87b7-bbe7f6a80fe8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "print(allFeatures)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['hours', 'income', 'age', 'education', 'child5', 'child13', 'child17', 'nonwhite', 'owned', 'unemp', 'poe_occupation']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "R-a1Wzi8C0_F",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "allFeatures.remove('mean_occupation')\n",
        "allFeatures.remove('woe_occupation')\n",
        "allFeatures.remove('label_occupation')\n",
        "allFeatures.remove('frequency_occupation')\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1RVNS5VDAp95",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "dataframe.head()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "inWZEFG8_FPT",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "finalModel[0].predict(allDataFramesAndSets[0])\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "C0WrVnn9W47g",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "print(dataframe.occupation.dtypes)\n",
        "print(dataframe.dtypes)\n",
        "print(dataframe.head(5))\n",
        "#dataframe.hours = dataframe.hours.astype('float64')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "n9rGzsNcReqR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}